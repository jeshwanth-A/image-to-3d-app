{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeshwanth-A/image-to-3d-app/blob/main/notebooks/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOOBWhQZ2LsC"
      },
      "source": [
        "# DefiDoza Training Notebook\n",
        "\n",
        "This notebook is self-contained and only for model training.\n",
        "\n",
        "- No local project files required\n",
        "- No LLM/agent code\n",
        "- Trained artifacts saved to Google Drive"
      ],
      "id": "yOOBWhQZ2LsC"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc-JkwNb2LsD",
        "outputId": "87fe864a-e313-4e7f-9137-deed24057f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Storage ready: /content/drive/MyDrive/defidoza/weights\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "DRIVE_BASE      = '/content/drive/MyDrive/defidoza'\n",
        "WEIGHTS_DIR     = os.path.join(DRIVE_BASE, 'weights')\n",
        "SCALER_PATH     = os.path.join(WEIGHTS_DIR, 'scaler.pkl')\n",
        "PYTORCH_WEIGHTS = os.path.join(WEIGHTS_DIR, 'pytorch_lstm.pth')\n",
        "TF_WEIGHTS      = os.path.join(WEIGHTS_DIR, 'tf_lstm.keras')\n",
        "RF_WEIGHTS      = os.path.join(WEIGHTS_DIR, 'rf_model.pkl')\n",
        "\n",
        "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
        "print(\"Storage ready:\", WEIGHTS_DIR)"
      ],
      "id": "kc-JkwNb2LsD"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3a_Ln-u2LsE",
        "outputId": "11f55a13-e28c-4724-a9d7-4dd2c7e7a45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: token=bitcoin days=90 epochs=50 seq_len=10 model=all\n",
            "------------------------------------------------------------\n",
            "Train seqs: 62 | Test seqs: 8\n",
            "[PyTorch] epoch 10/50 loss=0.067418\n",
            "[PyTorch] epoch 20/50 loss=0.046720\n",
            "[PyTorch] epoch 30/50 loss=0.047085\n",
            "[PyTorch] epoch 40/50 loss=0.042172\n",
            "[PyTorch] epoch 50/50 loss=0.042404\n",
            "Saved: /content/drive/MyDrive/defidoza/weights/pytorch_lstm.pth\n",
            "[PyTorch] MAE=1.530844 RMSE=1.534095\n",
            "Saved: /content/drive/MyDrive/defidoza/weights/tf_lstm.keras\n",
            "[TensorFlow] MAE=0.782864 RMSE=0.789609\n",
            "Saved: /content/drive/MyDrive/defidoza/weights/rf_model.pkl\n",
            "[RandomForest] MAE=1.563493 RMSE=1.567780\n",
            "------------------------------------------------------------\n",
            "Done. Files:\n",
            " - pytorch_lstm.pth\n",
            " - rf_model.pkl\n",
            " - scaler.pkl\n",
            " - tf_lstm.h5\n",
            " - tf_lstm.keras\n"
          ]
        }
      ],
      "source": [
        "import json, os, pickle, urllib.request, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "\n",
        "TOKENS = ['bitcoin', 'ethereum', 'solana', 'cardano', 'uniswap']\n",
        "FEATURE_COLS = ['price', 'volume', 'volatility', 'momentum', 'price_lag1']\n",
        "\n",
        "\n",
        "def fetch_and_parse(token_id, days):\n",
        "    url = (f'https://api.coingecko.com/api/v3/coins/{token_id}/market_chart'\n",
        "           f'?vs_currency=usd&days={days}&interval=daily')\n",
        "    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    with urllib.request.urlopen(req, timeout=20) as r:\n",
        "        data = json.loads(r.read().decode('utf-8'))\n",
        "\n",
        "    prices  = data.get('prices', [])\n",
        "    volumes = data.get('total_volumes', [])\n",
        "    if not prices:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
        "    df['volume'] = [v[1] for v in volumes[:len(df)]]\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_features(df):\n",
        "    df = df.copy()\n",
        "    prices = df['price'].values\n",
        "\n",
        "    ws = min(5, len(prices))\n",
        "    if len(prices) >= ws:\n",
        "        vol = np.std(np.lib.stride_tricks.sliding_window_view(prices, ws), axis=1)\n",
        "        df['volatility'] = np.pad(vol, (ws - 1, 0), mode='edge')\n",
        "    else:\n",
        "        df['volatility'] = 0.0\n",
        "\n",
        "    df['momentum'] = df['price'].pct_change().fillna(0.0)\n",
        "    df['price_lag1'] = df['price'].shift(1)\n",
        "    return df.dropna().reset_index(drop=True)\n",
        "\n",
        "\n",
        "def scale_data(df, fit=True):\n",
        "    df = df.copy()\n",
        "    if fit:\n",
        "        scaler = MinMaxScaler()\n",
        "        df[FEATURE_COLS] = scaler.fit_transform(df[FEATURE_COLS])\n",
        "        with open(SCALER_PATH, 'wb') as f:\n",
        "            pickle.dump(scaler, f)\n",
        "    else:\n",
        "        with open(SCALER_PATH, 'rb') as f:\n",
        "            scaler = pickle.load(f)\n",
        "        df[FEATURE_COLS] = scaler.transform(df[FEATURE_COLS])\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_sequences(df, seq_len):\n",
        "    data = df[FEATURE_COLS].values\n",
        "    seq_len = min(seq_len, len(data) - 1)\n",
        "    if seq_len < 1:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    pi = FEATURE_COLS.index('price')\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i + seq_len])\n",
        "        y.append(data[i + seq_len][pi])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "class PricePredictorPT(nn.Module):\n",
        "    def __init__(self, input_size, hidden=64, layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size, hidden_size=hidden, num_layers=layers,\n",
        "            batch_first=True, dropout=(dropout if layers > 1 else 0.0)\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "\n",
        "def build_tf_model(shape):\n",
        "    m = Sequential([\n",
        "        LSTM(64, input_shape=shape),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    m.compile(optimizer='adam', loss='mse')\n",
        "    return m\n",
        "\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return mae, rmse\n",
        "\n",
        "\n",
        "def train_once(token='bitcoin', days=60, epochs=50, seq_len=10, model='all'):\n",
        "    print(f'Config: token={token} days={days} epochs={epochs} seq_len={seq_len} model={model}')\n",
        "    print('-' * 60)\n",
        "\n",
        "    df = fetch_and_parse(token, days)\n",
        "    if df is None or len(df) < 15:\n",
        "        print(\"Not enough data. Increase days.\")\n",
        "        return\n",
        "\n",
        "    df = compute_features(df)\n",
        "\n",
        "    split = int(len(df) * 0.8)\n",
        "    train_df = df.iloc[:split].copy()\n",
        "    test_df  = df.iloc[split:].copy()\n",
        "\n",
        "    # Fit scaler on train only (no leakage)\n",
        "    train_df = scale_data(train_df, fit=True)\n",
        "    test_df  = scale_data(test_df,  fit=False)\n",
        "\n",
        "    Xtr, ytr = create_sequences(train_df, seq_len)\n",
        "    Xte, yte = create_sequences(test_df,  seq_len)\n",
        "\n",
        "    if len(Xtr) == 0:\n",
        "        print(\"Not enough sequences. Increase days or reduce seq_len.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Train seqs: {len(Xtr)} | Test seqs: {len(Xte)}\")\n",
        "\n",
        "    # ── PyTorch ──\n",
        "    if model in ('pytorch', 'all'):\n",
        "        dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        m = PricePredictorPT(input_size=Xtr.shape[2]).to(dev)\n",
        "        opt = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
        "        crit = nn.MSELoss()\n",
        "\n",
        "        Xt = torch.tensor(Xtr, dtype=torch.float32).to(dev)\n",
        "        yt = torch.tensor(ytr, dtype=torch.float32).unsqueeze(1).to(dev)\n",
        "\n",
        "        step = max(1, epochs // 5)\n",
        "        for e in range(epochs):\n",
        "            m.train()\n",
        "            loss = crit(m(Xt), yt)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            if (e + 1) % step == 0:\n",
        "                print(f\"[PyTorch] epoch {e+1}/{epochs} loss={loss.item():.6f}\")\n",
        "\n",
        "        torch.save(m.state_dict(), PYTORCH_WEIGHTS)\n",
        "        print(\"Saved:\", PYTORCH_WEIGHTS)\n",
        "\n",
        "        if len(Xte):\n",
        "            m.eval()\n",
        "            with torch.no_grad():\n",
        "                pred = m(torch.tensor(Xte, dtype=torch.float32).to(dev)).cpu().numpy().flatten()\n",
        "            mae, rmse = metrics(yte, pred)\n",
        "            print(f\"[PyTorch] MAE={mae:.6f} RMSE={rmse:.6f}\")\n",
        "\n",
        "    # ── TensorFlow ──\n",
        "    if model in ('tensorflow', 'all'):\n",
        "        m = build_tf_model((Xtr.shape[1], Xtr.shape[2]))\n",
        "        m.fit(Xtr, ytr, epochs=epochs, batch_size=max(1, len(Xtr)//10), verbose=0)\n",
        "        m.save(TF_WEIGHTS)\n",
        "        print(\"Saved:\", TF_WEIGHTS)\n",
        "\n",
        "        if len(Xte):\n",
        "            pred = m.predict(Xte, verbose=0).flatten()\n",
        "            mae, rmse = metrics(yte, pred)\n",
        "            print(f\"[TensorFlow] MAE={mae:.6f} RMSE={rmse:.6f}\")\n",
        "\n",
        "    # ── RandomForest ──\n",
        "    if model in ('randomforest', 'all'):\n",
        "        rf = RandomForestRegressor(n_estimators=200, max_depth=12, random_state=42, n_jobs=-1)\n",
        "        rf.fit(Xtr.reshape(len(Xtr), -1), ytr)\n",
        "        with open(RF_WEIGHTS, 'wb') as f:\n",
        "            pickle.dump(rf, f)\n",
        "        print(\"Saved:\", RF_WEIGHTS)\n",
        "\n",
        "        if len(Xte):\n",
        "            pred = rf.predict(Xte.reshape(len(Xte), -1))\n",
        "            mae, rmse = metrics(yte, pred)\n",
        "            print(f\"[RandomForest] MAE={mae:.6f} RMSE={rmse:.6f}\")\n",
        "\n",
        "    print('-' * 60)\n",
        "    print(\"Done. Files:\")\n",
        "    for fn in sorted(os.listdir(WEIGHTS_DIR)):\n",
        "        print(\" -\", fn)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# COLAB FORM \"GUI\"\n",
        "# =========================\n",
        "#@title Train Settings (this is the GUI)\n",
        "token = \"bitcoin\" #@param [\"bitcoin\",\"ethereum\",\"solana\",\"cardano\",\"uniswap\"]\n",
        "days = 90 #@param {type:\"integer\"}\n",
        "epochs = 50 #@param {type:\"integer\"}\n",
        "seq_len = 10 #@param {type:\"integer\"}\n",
        "model = \"all\" #@param [\"all\",\"pytorch\",\"tensorflow\",\"randomforest\"]\n",
        "\n",
        "# Run training with the selected settings:\n",
        "train_once(token, days, epochs, seq_len, model)"
      ],
      "id": "J3a_Ln-u2LsE"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}